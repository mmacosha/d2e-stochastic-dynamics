{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./external/sg3')\n",
    "sys.path.append('./external/torch_hmc')\n",
    "\n",
    "\n",
    "from sb.nn.reward import ClsReward\n",
    "from sb.data.datasets import ClsRewardDist, MixOfGaussians\n",
    "from sb.utils import plot_annotated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "\n",
    "# rwd_dist = ClsRewardDist('cifar10-gan-z256', 'cifar10-cls', 50, [5], 'sum', device)\n",
    "rwd_dist = ClsRewardDist('cifar10-stylegan', 'cifar10-cls', 50, [5], 'sum', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(fn, x):\n",
    "    x_ = x.detach().clone().requires_grad_(True)    \n",
    "    o = fn(x_)\n",
    "    o.sum().backward()\n",
    "    return o, x_.grad\n",
    "\n",
    "\n",
    "def mala_correction(x, logp_x, grad_logp_x, y, logp_y, grad_logp_y, dt):\n",
    "    adj = logp_y - logp_x + \\\n",
    "          (y - x - dt * grad_logp_x).pow(2).sum(1) / (4 * dt) - \\\n",
    "          (x - y - dt * grad_logp_y).pow(2).sum(1) / (4 * dt)\n",
    "\n",
    "    adj = torch.minimum(torch.ones_like(adj), adj.exp())\n",
    "    return torch.rand_like(adj) < adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'ula' # ula, mala\n",
    "\n",
    "# x = torch.randn(512, 256, device=device)\n",
    "x = torch.randn(128, 512, device=device)\n",
    "dt = 0.1\n",
    "num_steps = 500\n",
    "anneal_value = 0.1\n",
    "\n",
    "lmbda = 0.9\n",
    "grad_lmbda = 0.0\n",
    "alpha = math.exp(math.log(anneal_value) / num_steps)\n",
    "\n",
    "prev_z = None\n",
    "ema_grad = 0\n",
    "precision, mean_log_reward, adj_fracs = [], [], []\n",
    "for it in trange(num_steps):\n",
    "    if method == 'ula':\n",
    "        _, grad = compute_grad(rwd_dist.log_density, x)\n",
    "        ema_grad = grad_lmbda * ema_grad + (1 - grad_lmbda) * grad\n",
    "\n",
    "        curr_z = torch.randn_like(x)\n",
    "        z = curr_z if prev_z is None else (curr_z + prev_z) / 2\n",
    "        prev_z = curr_z\n",
    "        \n",
    "        y = x + ema_grad * dt + math.sqrt(2 * dt) * z\n",
    "        \n",
    "        x = lmbda * x + (1 - lmbda) * y\n",
    "        adj_fracs.append(1.0)\n",
    "    \n",
    "    elif method == 'mala':\n",
    "        logp_x, grad_logp_x = compute_grad(rwd_dist.log_density, x)\n",
    "\n",
    "        z = torch.randn_like(x)\n",
    "        y = x + grad_logp_x * dt + math.sqrt(2 * dt) * z\n",
    "\n",
    "        logp_y, grad_logp_y = compute_grad(rwd_dist.log_density, y)\n",
    "\n",
    "        adj = mala_correction(x, logp_x, grad_logp_x, \n",
    "                            y, logp_y, grad_logp_y, \n",
    "                            dt)\n",
    "        adj_fracs.append(adj.float().mean().item())\n",
    "        x[adj] = y[adj]\n",
    "\n",
    "    dt *= alpha \n",
    "\n",
    "    with torch.no_grad():\n",
    "        img = rwd_dist.reward.generator(x)\n",
    "        img = img * 0.5 + 0.5\n",
    "        \n",
    "        probas = rwd_dist.reward.classifier(img).softmax(dim=1)\n",
    "        (p, c) = probas.max(dim=1)\n",
    "        \n",
    "        mean_log_rwd = probas[:, 5].log().mean().item()\n",
    "        prc = (c == 5).float().mean().item()\n",
    "    \n",
    "    precision.append(prc)\n",
    "    mean_log_reward.append(mean_log_rwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 1, figsize=(12, 10))\n",
    "names = ['Precision', 'Mean Log Reward', 'Acceptance Rate']\n",
    "\n",
    "for i, graph  in enumerate([\n",
    "    precision, mean_log_reward, adj_fracs\n",
    "]):\n",
    "    ax[i].set_title(names[i])\n",
    "    ax[i].plot(graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    img = rwd_dist.reward.generator(x)\n",
    "    img = torch.clip(img * 0.5 + 0.5, 0, 1)\n",
    "    probas = rwd_dist.reward.classifier(img).softmax(dim=1)\n",
    "    (p, c) = probas.max(dim=1)\n",
    "    \n",
    "    mean_log_rwd = probas[:, 5].log().mean()\n",
    "    precision = (c == 5).float().mean()\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.2f}, Mean log reward: {mean_log_rwd:.3f}\")\n",
    "_ = plot_annotated_images(img[:16], (p[:16], c[:16]), n_col=4, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hamiltorch\n",
    "hamiltorch.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.randn(512, device=device)\n",
    "\n",
    "sampler=hamiltorch.Sampler.HMC\n",
    "integrator=hamiltorch.Integrator.IMPLICIT\n",
    "\n",
    "\n",
    "def _log_gensity(x):\n",
    "    x = x.reshape(1, -1)\n",
    "    density = rwd_dist.log_density(x)\n",
    "    return density[0]\n",
    "\n",
    "xt = params_hmc = hamiltorch.sample(\n",
    "    log_prob_func=_log_gensity, \n",
    "    params_init=x0,  \n",
    "    num_samples=64, \n",
    "    step_size=0.08, \n",
    "    num_steps_per_sample=10,\n",
    "    sampler=sampler, \n",
    "    integrator=integrator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.stack(xt[::4])\n",
    "    img = rwd_dist.reward.generator(x)\n",
    "    img = torch.clip(img * 0.5 + 0.5, 0, 1)\n",
    "    probas = rwd_dist.reward.classifier(img).softmax(dim=1)\n",
    "\n",
    "(p, c) = probas.max(dim=1)\n",
    "mean_log_rwd = probas[:, 5].log().mean()\n",
    "\n",
    "print(\n",
    "    f\"{img.shape[0]=} |\",\n",
    "    f\" Precision: {(c == 5).float().mean():.2f} |\",\n",
    "    f\"Mean log reward: {mean_log_rwd:.3f}\"\n",
    ")\n",
    "_ = plot_annotated_images(img[:32], (p[:32], c[:32]), n_col=4, figsize=(12, 24))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sg3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
